# ğŸ§  Atelier 1 â€“ K-Means (ImplÃ©mentation From Scratch)

## ğŸ¯ Objectif du TP

Lâ€™objectif de ce travail pratique est dâ€™implÃ©menter lâ€™algorithme de **K-Means** depuis zÃ©ro, en utilisant uniquement **NumPy** (sans scikit-learn), puis dâ€™ajouter des fonctions pour Ã©valuer la qualitÃ© du clustering Ã  chaque itÃ©ration Ã  lâ€™aide de deux mesures :
- **Inertie intra-classes** (Within-Cluster Sum of Squares â€“ WCSS)
- **Inertie inter-classes** (Between-Cluster Sum of Squares â€“ BCSS)

---

## ğŸ§© Travail Ã  rÃ©aliser

### 1ï¸âƒ£ GÃ©nÃ©ration des donnÃ©es
- GÃ©nÃ©rer des donnÃ©es alÃ©atoires en 2 dimensions Ã  lâ€™aide de `make_blobs`.
- Visualiser les points Ã  lâ€™aide de `matplotlib` ou `seaborn`.

```python
from sklearn.datasets import make_blobs
X_train, true_labels = make_blobs(n_samples=100, centers=4, random_state=42)
```

---

### 2ï¸âƒ£ ImplÃ©mentation de la distance euclidienne

```python
def euclid(centre, data):
    return np.sqrt(np.sum((centre - data)**2, axis=1))
```

---

### 3ï¸âƒ£ ImplÃ©mentation de K-Means

CrÃ©er une classe `Kmeans` avec :
- `__init__` pour initialiser le nombre de clusters et le nombre dâ€™itÃ©rations.
- `fit(X_train)` pour :
  - Initialiser les centres alÃ©atoirement.
  - RÃ©pÃ©ter lâ€™affectation et la mise Ã  jour des centres.
  - Calculer les inerties intra et inter Ã  chaque itÃ©ration.

---

### 4ï¸âƒ£ Fonctions de calcul des inerties

```python
def inertia_intra(X, labels, centres):
    X = np.asarray(X)
    centres = np.asarray(centres)
    s = 0.0
    for k in range(len(centres)):
        members = X[labels == k]
        if members.size == 0:
            continue
        diffs = members - centres[k]
        s += float(np.sum(diffs * diffs))
    return s

def inertia_inter(X, labels, centres):
    X = np.asarray(X)
    centres = np.asarray(centres)
    mu = np.mean(X, axis=0)
    total = 0.0
    for k, c in enumerate(centres):
        n_k = np.sum(labels == k)
        if n_k == 0:
            continue
        diff = c - mu
        total += n_k * float(np.dot(diff, diff))
    return total
```

---

### 5ï¸âƒ£ IntÃ©gration dans la classe K-Means

Dans la mÃ©thode `fit`, afficher Ã  **chaque itÃ©ration** :

```python
intra = inertia_intra(X, labels, new_centres)
inter = inertia_inter(X, labels, new_centres)
print(f"Iteration {t:02d} â€” Intra: {intra:.4f} | Inter: {inter:.4f}")
```

---

### 6ï¸âƒ£ Visualisation du rÃ©sultat final

```python
plt.scatter(X_train[:, 0], X_train[:, 1], c=labels, cmap='viridis')
plt.scatter(centres[:, 0], centres[:, 1], marker='+', s=200, c='red')
plt.title("RÃ©sultat final du K-Means")
plt.show()
```

---

## ğŸ§® RÃ©sultat attendu

- Ã€ chaque itÃ©ration, la console doit afficher :
  ```
  Iteration 01 â€” Intra: 4563.12 | Inter: 37921.45
  Iteration 02 â€” Intra: 2389.54 | Inter: 38452.90
  ...
  ```
- Une convergence visible des centres vers les clusters.
- Un graphique avec les points colorÃ©s et les centres marquÃ©s dâ€™un `+`.

---

## âš™ï¸ Technologies utilisÃ©es
- **Python 3.x**
- **NumPy**
- **Matplotlib / Seaborn**
- **Scikit-learn** (uniquement pour la gÃ©nÃ©ration des donnÃ©es `make_blobs`)

---

## ğŸ“ Structure recommandÃ©e

```
Atelier1_Kmeans/
â”‚
â”œâ”€â”€ Atelier1_Kmeans_donnees_alÃ©atoires.ipynb   # Notebook principal
â”œâ”€â”€ README.md                                  # Ce fichier
â””â”€â”€ data/                                      # (optionnel)
```
